{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: GeForce GTX 980M (CNMeM is disabled)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from optparse import OptionParser\n",
    "import pickle\n",
    "\n",
    "# Required libraries\n",
    "import h5py\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.layers.normalization import BatchNormalization as BN\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "sys.path.append('/work/code/repo/d-script/')\n",
    "# d-script imports\n",
    "from data_iters.minibatcher import MiniBatcher\n",
    "from data_iters.iam_hdf5_iterator import IAM_MiniBatcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hdf5_file = h5py.File('../../../../docingest/lines.hdf5','r')\n",
    "author_hdf5_file = h5py.File('../../../../docingest/author_lines.hdf5','r')\n",
    "file_list = hdf5_file.keys()\n",
    "num_authors=47\n",
    "num_forms_per_author=500\n",
    "shingle_dim=(120,120)\n",
    "use_form=True\n",
    "\n",
    "batch_size=32\n",
    "lr = 0.01\n",
    "total_iters=1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling model\n",
      "Finished compilation\n"
     ]
    }
   ],
   "source": [
    "# Get a shingle from a line with dimension shingle_dim\n",
    "def get_shingle(original_line, shingle_dim):\n",
    "    # Pull shingle from the line\n",
    "    (height, width) = original_line.shape\n",
    "    max_x = max(width - shingle_dim[1], 0)\n",
    "    max_y = max(height - shingle_dim[0], 0)\n",
    "    x_start = random.randint(0, max_x)\n",
    "    y_start = random.randint(0, max_y)\n",
    "    if width < shingle_dim[1] or height < shingle_dim[0]: # The line is too small in at least one access\n",
    "        output_arr = np.zeros(shingle_dim)\n",
    "        output_arr.fill(255)\n",
    "        output_arr[:height,:width] = original_line[:min(height, shingle_dim[0]), :min(width, shingle_dim[1])]\n",
    "        return output_arr\n",
    "    else:\n",
    "        return original_line[y_start:y_start+ shingle_dim[0], x_start:x_start+shingle_dim[1]]\n",
    "\n",
    "# From an HDF5 file, a list of author ID's, return a minibatch\n",
    "def get_batch( author_hdf5_file, author_ids, shingle_size=(120,120), data_size=32 ):\n",
    "    \n",
    "    author_keys = author_ids.keys()\n",
    "    author_rands = np.random.randint(0, len(author_keys), data_size)\n",
    "\n",
    "    author_batch = np.zeros( (data_size, shingle_size[0], shingle_size[1]))\n",
    "    author_truth = np.zeros( data_size )\n",
    "    for i, author_rand in enumerate(author_rands):\n",
    "        author_group = author_hdf5_file[ author_keys[author_rand] ]\n",
    "        author_batch[i,:,:] = get_shingle( sample_dictionary( author_group ).value , shingle_size)\n",
    "        author_truth[i] = author_ids[ author_keys[author_rand] ]\n",
    "        \n",
    "    return author_batch, author_truth\n",
    "\n",
    "if True:\n",
    "    model = Sequential()\n",
    "    model.add(Convolution2D(48, 12, 12,\n",
    "                        border_mode='valid',\n",
    "                        input_shape=(1, shingle_dim[0], shingle_dim[1])))\n",
    "\n",
    "    model.add(BN())\n",
    "    #model.add(PReLU())\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Convolution2D(48, 6, 6))\n",
    "    model.add(BN())\n",
    "    model.add(Activation('relu'))\n",
    "    #model.add(PReLU())\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    #model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Convolution2D(128, 6, 6, border_mode = 'valid'))\n",
    "    model.add(BN())\n",
    "    model.add(Activation('relu'))\n",
    "    #    model.add(PReLU())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    #    #model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Convolution2D(128, 3, 3, border_mode = 'valid'))\n",
    "    model.add(BN())\n",
    "    model.add(Activation('relu'))\n",
    "    #model.add(PReLU())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    #model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128))\n",
    "    model.add(BN())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(128))\n",
    "    model.add(BN())\n",
    "    model.add(Activation('relu'))\n",
    "    #model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Dense(num_authors))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    print \"Compiling model\"\n",
    "    sgd = SGD(lr=0.1, decay=1e-6, momentum=0.7, nesterov=False)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=sgd)\n",
    "    print \"Finished compilation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.load_weights('fielnet.hdf5')\n",
    "author_ids = pickle.load(open('fielauthors.p'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "global name 'sample_dictionary' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-590561f4d42c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;33m(\u001b[0m\u001b[0mX_s\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_s\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mauthor_hdf5_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mauthor_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mX_s\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1.0\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mX_s\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m255.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mX_s\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_s\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mX_s\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrandangle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_s\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mY_s\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY_s\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_authors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-17-6ad00e2ac787>\u001b[0m in \u001b[0;36mget_batch\u001b[1;34m(author_hdf5_file, author_ids, shingle_size, data_size)\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mauthor_rand\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mauthor_rands\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[0mauthor_group\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mauthor_hdf5_file\u001b[0m\u001b[1;33m[\u001b[0m \u001b[0mauthor_keys\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mauthor_rand\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m         \u001b[0mauthor_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_shingle\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0msample_dictionary\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mauthor_group\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mshingle_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m         \u001b[0mauthor_truth\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mauthor_ids\u001b[0m\u001b[1;33m[\u001b[0m \u001b[0mauthor_keys\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mauthor_rand\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: global name 'sample_dictionary' is not defined"
     ]
    }
   ],
   "source": [
    "(X_s, Y_s) = get_batch(author_hdf5_file, author_ids, data_size=32*10)\n",
    "X_s = 1.0 - X_s / 255.0\n",
    "X_s = np.expand_dims(X_s, 1)\n",
    "X_s = randangle(X_s)\n",
    "Y_s = to_categorical(Y_s, num_authors)\n",
    "model.fit(X_s, Y_s, batch_size=batch_size, nb_epoch=1, show_accuracy=True, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
