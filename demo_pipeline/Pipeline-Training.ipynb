{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: GeForce GTX TITAN X (CNMeM is disabled)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import sys\n",
    "import logging\n",
    "sys.path.append('../')\n",
    "\n",
    "# Neural network stuff\n",
    "from data_iters.hdf5_iterator import Hdf5MiniBatcher\n",
    "from data_iters.minibatcher import MiniBatcher\n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from fielutil import load_verbatimnet\n",
    "from featextractor import extract_imfeats_debug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File names\n",
    "\n",
    "You will require:\n",
    "1. HDF5 Files:\n",
    "    a. Author-Lines\n",
    "    b. Flat Images\n",
    "2. Params (for the neural network you're looking at)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Do you want to load the features in? Or save them to a file?\n",
    "load_features = False\n",
    "\n",
    "# All the images that you require extraction should be in this HDF5 file\n",
    "# hdf5authors='nmecdata/nmec_scaled_author_form.hdf5'\n",
    "hdf5authors='/memory/nmec_scaled_author_form.hdf5'\n",
    "hdf5images='nmecdata/nmec_scaled_flat.hdf5'\n",
    "hdf5authors='/fileserver/iam/iam-processed/words/author_words.hdf5'\n",
    "\n",
    "# This is the file that you will load the features from or save the features to\n",
    "# featurefile = 'icdar13data/benchmarking-processed/icdar13be_fiel657.npy'\n",
    "# featurefile = 'icdar13data/experimental-processed/icdar13ex_fiel657.npy'\n",
    "featurefile = 'nmecdata/nmec_fiel657_features.npy'\n",
    "\n",
    "# This is the neural networks and parameters you are deciding to use\n",
    "paramsfile = '/fileserver/iam/iam-processed/models/fiel_657.hdf5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labels = h5py.File(hdf5authors, 'r')\n",
    "num_authors=len(labels)\n",
    "num_forms_per_author=-1\n",
    "shingle_dim=(56,56)\n",
    "batch_size=3200\n",
    "iterations = 1000\n",
    "lr = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define your model\n",
    "\n",
    "Here, we're using the Fiel Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Establishing Fiel's verbatim network\n",
      "Loaded neural network up to fc7 layer"
     ]
    }
   ],
   "source": [
    "vnet = load_verbatimnet( 'fc7', paramsfile=paramsfile, compiling=False )\n",
    "vnet.add(Dense(num_authors))\n",
    "vnet.add(Activation('softmax'))\n",
    "sgd = SGD(lr=lr, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "vnet.compile(loss='categorical_crossentropy', optimizer=sgd)\n",
    "print \"Finished compilation\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Minibatcher (to load in your data for each batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# logging.getLogger('data_iters.hdf5_iterator').setLevel(logging.DEBUG)\n",
    "nmec_m = Hdf5MiniBatcher(hdf5authors, num_authors, num_forms_per_author,\n",
    "                            shingle_dim=shingle_dim, default_mode=MiniBatcher.TRAIN,\n",
    "                            batch_size=batch_size, add_rotation=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train your model for however many specified iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for batch_iter in range(iterations):\n",
    "    (X_train,Y_train) = nmec_m.get_train_batch()\n",
    "    X_train = 1.0 - X_train / 255.0\n",
    "    X_train = np.expand_dims(X_train, 1)\n",
    "    Y_train = to_categorical(Y_train, num_authors)\n",
    "    vnet.fit(X_train, Y_train, batch_size=batch_size, nb_epoch=1, show_accuracy=True, verbose=1)\n",
    "    print \"Finished training on the \"+str(i)+\"th batch\"\n",
    "    if (batch_iter % 20)==0 and batch_iter != 0:\n",
    "        model.save_weights('fielnet-nmec.hdf5', overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
