{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference Pipeline\n",
    "\n",
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: GeForce GTX 980\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import sys\n",
    "import logging\n",
    "sys.path.append('..')\n",
    "\n",
    "# Neural network stuff\n",
    "from fielutil import load_verbatimnet\n",
    "from featextractor import extract_imfeats_debug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Do you want to load the features in? Or save them to a file?\n",
    "load_features = False\n",
    "\n",
    "# All the images that you require extraction should be in this HDF5 file\n",
    "# hdf5images='icdar13data/benchmarking-processed/icdar_be.hdf5'\n",
    "# hdf5images = 'icdar13data/experimental-processed/icdar13_ex.hdf5'\n",
    "hdf5images='nmecdata/nmec_scaled_flat.hdf5'\n",
    "\n",
    "# This is the file that you will load the features from or save the features to\n",
    "# featurefile = 'icdar13data/benchmarking-processed/icdar13be_fiel657.npy'\n",
    "# featurefile = 'icdar13data/experimental-processed/icdar13ex_fiel657.npy'\n",
    "featurefile = 'nmecdata/nmec_fiel657_features.npy'\n",
    "\n",
    "# This is the neural networks and parameters you are deciding to use\n",
    "paramsfile = '/fileserver/iam/iam-processed/models/fiel_657.hdf5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full image HDF5 file\n",
    "\n",
    "Each entry in the HDF5 file is a full image/form/document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labels = h5py.File(hdf5images).keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load feature extractor neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Establishing Fiel's verbatim network\n",
      "Compiled neural network up to FC7 layer\n"
     ]
    }
   ],
   "source": [
    "vnet = load_verbatimnet( 'fc7', paramsfile=paramsfile )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image features\n",
    "\n",
    "Currently taken as averages of all shard features in the image. You can either load them or extract everything manually, depending on if you have the .npy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin extracting features fromnmecdata/nmec_scaled_flat.hdf5\n",
      "Loaded 20375 shards in and predicting on image FR-003-001.tif\n",
      "20375/20375 [==============================] - 7s     \n",
      "Loaded 20375 shards in and predicting on image FR-003-002.tif\n",
      "20375/20375 [==============================] - 7s     \n",
      "Loaded 20375 shards in and predicting on image FR-003-003.tif\n",
      "20375/20375 [==============================] - 7s     \n",
      "Loaded 20375 shards in and predicting on image FR-003-004.tif\n",
      "20375/20375 [==============================] - 7s     \n",
      "Loaded 20375 shards in and predicting on image FR-003-005.tif\n",
      "20375/20375 [==============================] - 7s     \n",
      "Loaded 20375 shards in and predicting on image FR-003-006.tif\n",
      "20375/20375 [==============================] - 7s     \n",
      "Loaded 20375 shards in and predicting on image FR-003-007.tif\n",
      "20375/20375 [==============================] - 7s     \n",
      "Loaded 20375 shards in and predicting on image FR-003-008.tif\n",
      "20375/20375 [==============================] - 7s     \n",
      "Loaded 20375 shards in and predicting on image FR-004-001.tif\n",
      "20375/20375 [==============================] - 7s     \n",
      "Loaded 20375 shards in and predicting on image FR-004-002.tif\n",
      "20375/20375 [==============================] - 7s     \n",
      "Loaded 20375 shards in and predicting on image FR-004-003.tif\n",
      "20375/20375 [==============================] - 7s     \n",
      "Loaded 20375 shards in and predicting on image FR-004-004.tif\n",
      "20375/20375 [==============================] - 7s     \n",
      "Loaded 20375 shards in and predicting on image FR-004-005.tif\n",
      "20375/20375 [==============================] - 7s     "
     ]
    }
   ],
   "source": [
    "logging.getLogger('featextractor').setLevel(logging.DEBUG)\n",
    "if load_features:\n",
    "    print \"Loading features in from \"+featurefile\n",
    "    imfeats = np.load(featurefile)\n",
    "else:\n",
    "    print \"Begin extracting features from\"+hdf5images\n",
    "    imfeats = extract_imfeats_debug( hdf5images, vnet )\n",
    "    np.save( featurefile, imfeats )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "imfeats = ( imfeats.T / np.linalg.norm( imfeats, axis=1 ) ).T\n",
    "F = imfeats.dot(imfeats.T)\n",
    "np.fill_diagonal( F , -1 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate classifier on HDF5 file (ICDAR 2013)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Top k (soft criteria)\n",
    "k = 10\n",
    "# Max top (hard criteria)\n",
    "maxtop = 2\n",
    "\n",
    "# Run through the adjacency matrix\n",
    "softcorrect = 0\n",
    "hardcorrect = 0\n",
    "totalnum = 0\n",
    "for j, i in enumerate(F):\n",
    "    topk = i.argsort()[-k:]\n",
    "    # Soft criteria\n",
    "    if j/4 in topk/4:\n",
    "        softcorrect += 1\n",
    "    totalnum +=1\n",
    "    # Hard criteria\n",
    "    hardcorrect+= sum([1 for jj in (j/4 == topk[-maxtop:]/4) if jj])\n",
    "    \n",
    "# Print out results    \n",
    "print \"Top %d (soft criteria) = %f\" %( k, (softcorrect+0.0) / totalnum )\n",
    "print \"Top %d (hard criteria) = %f\" %( k, (hardcorrect+0.0) / totalnum / maxtop )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
