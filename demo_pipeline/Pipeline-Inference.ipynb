{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference Pipeline\n",
    "\n",
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import sys\n",
    "import logging\n",
    "sys.path.append('..')\n",
    "\n",
    "# Neural network stuff\n",
    "from fielutil import load_verbatimnet\n",
    "from featextractor import extract_imfeats\n",
    "\n",
    "# Logging\n",
    "# logging.getLogger('featextractor').setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Do you want to load the features in? Or save them to a file?\n",
    "load_features = True\n",
    "\n",
    "# All the images that you require extraction should be in this HDF5 file\n",
    "# hdf5images='icdar13data/benchmarking-processed/icdar_be.hdf5'\n",
    "# hdf5images = 'icdar13data/experimental-processed/icdar13_ex.hdf5'\n",
    "# hdf5images='nmecdata/nmec_scaled_flat.hdf5'\n",
    "hdf5images='nmecdata/flat_nmec_bin_uint8.hdf5'\n",
    "\n",
    "# This is the file that you will load the features from or save the features to\n",
    "# featurefile = 'icdar13data/benchmarking-processed/icdar13be_fiel657.npy'\n",
    "# featurefile = 'icdar13data/experimental-processed/icdar13ex_fiel657.npy'\n",
    "featurefile = 'nmecdata/features/nmec_bw_fiel657_features_steps5_thresh.005.npy'\n",
    "# featurefile = 'nmecdata/nmec_bw_fiel657_features_steps5_mean500.npy'\n",
    "\n",
    "# This is the neural networks and parameters you are deciding to use\n",
    "paramsfile = '/fileserver/iam/iam-processed/models/fiel_657.hdf5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full image HDF5 file\n",
    "\n",
    "Each entry in the HDF5 file is a full image/form/document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labels = h5py.File(hdf5images).keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load feature extractor neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Establishing Fiel's verbatim network\n",
      "Loaded neural network up to fc7 layer\n"
     ]
    }
   ],
   "source": [
    "vnet = load_verbatimnet( 'fc7', paramsfile=paramsfile )\n",
    "vnet.compile(loss='mse', optimizer='sgd')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image features\n",
    "\n",
    "Currently taken as averages of all shard features in the image. You can either load them or extract everything manually, depending on if you have the .npy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading features in from nmecdata/features/nmec_bw_fiel657_features_steps5_thresh.005.npy\n",
      "Loaded features\n"
     ]
    }
   ],
   "source": [
    "if load_features:\n",
    "    print \"Loading features in from \"+featurefile\n",
    "    imfeats = np.load(featurefile)\n",
    "    print \"Loaded features\"\n",
    "else:\n",
    "    print \"Begin extracting features from \"+hdf5images\n",
    "    imfeats = extract_imfeats( hdf5images, vnet, steps=(5,5), compthresh=500 )\n",
    "    print h5py.File(hdf5images).keys()\n",
    "    np.save( featurefile, imfeats )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "imfeats = ( imfeats.T / np.linalg.norm( imfeats, axis=1 ) ).T\n",
    "F = imfeats.dot(imfeats.T)\n",
    "np.fill_diagonal( F , -1 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate classifier on HDF5 file \n",
    "\n",
    "You'll need to set the number of examples per image as follows:\n",
    "1. IAM: Not Implemented\n",
    "2. ICDAR 2013: g=4\n",
    "3. NMEC: g=8\n",
    "\n",
    "Two criteria matched are:\n",
    "1. Precision (hard)\n",
    "2. Recall (soft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 (soft criteria) = 0.362500\n",
      "Top 10 (hard criteria) = 0.006944\n"
     ]
    }
   ],
   "source": [
    "# Top k (soft criteria)\n",
    "k = 10\n",
    "# Max top (hard criteria)\n",
    "maxtop = 3\n",
    "# Number of examples per image\n",
    "g = 8\n",
    "\n",
    "# Run through the adjacency matrix\n",
    "softcorrect = 0\n",
    "hardcorrect = 0\n",
    "totalnum = 0\n",
    "for j, i in enumerate(F):\n",
    "    topk = i.argsort()[-k:]\n",
    "    # Soft criteria\n",
    "    if j/g in topk/g:\n",
    "        softcorrect += 1\n",
    "    totalnum +=1\n",
    "    # Hard criteria\n",
    "    hardsample = sum([1 for jj in (j/g == topk[-maxtop:]/g) if jj])\n",
    "    if hardsample==maxtop:\n",
    "        hardcorrect += 1\n",
    "    \n",
    "# Print out results    \n",
    "print \"Top %d (soft criteria) = %f\" %( k, (softcorrect+0.0) / totalnum )\n",
    "print \"Top %d (hard criteria) = %f\" %( k, (hardcorrect+0.0) / totalnum )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "plt.plot(range(16),np.log(F[2][0:16]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
