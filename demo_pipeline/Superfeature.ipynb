{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: GeForce GTX TITAN X (CNMeM is disabled)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import logging\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import defaultdict, namedtuple\n",
    "from optparse import OptionParser\n",
    "\n",
    "# Required libraries\n",
    "import h5py\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.layers.normalization import BatchNormalization as BN\n",
    "\n",
    "import IPython.display\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "# d-script imports\n",
    "from data_iters.minibatcher import MiniBatcher\n",
    "from data_iters.iam_hdf5_iterator import IAM_MiniBatcher\n",
    "from fielutil import fielnet\n",
    "import viz_tools.array_to_png as a2p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hdf5_file = '/fileserver/icdar13/benchmarking-processed/author_icdar_be.hdf5'\n",
    "neural_network_params = '../convnets/fielnet/fielnet.hdf5'\n",
    "num_authors=100\n",
    "num_forms_per_author=-1\n",
    "shingle_dim=(120,120)\n",
    "use_form=True\n",
    "\n",
    "batch_size=32\n",
    "lr = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Classification Minibatcher\n",
    "### Pat's Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "class StepShingler:\n",
    "    ShingleSize=namedtuple('ShingleSize', ['rows','cols'])\n",
    "    \n",
    "    def __init__(self, img, \n",
    "                 hstep, vstep, \n",
    "                 shingle_size=ShingleSize(rows=120,cols=120)):\n",
    "        \"\"\" given an image of a document fragment, \n",
    "        produce deterministic shingles from that document\n",
    "        \n",
    "        Arguments:\n",
    "            img -- array (numpy array interface)\n",
    "            hstep -- number of columns to step between shingles\n",
    "            vstep -- number of rows to step between shingles\n",
    "            shingle_size -- ROWS, COLS format.\n",
    "        \"\"\"\n",
    "        self.img = img\n",
    "        self.shingle_size = StepShingler.ShingleSize(*shingle_size)\n",
    "        self.vstep = vstep\n",
    "        self.hstep = hstep\n",
    "        \n",
    "        # warn if danger of leaving off right or bottom edge\n",
    "        h_step_space = img.shape[1] - self.shingle_size.cols\n",
    "        # number of pixels left over on right edge\n",
    "        h_step_margin = h_step_space % hstep\n",
    "        if h_step_margin != 0:\n",
    "            logger = logging.getLogger(__name__)\n",
    "            logger.debug(\"Horizontal step/window settings do not divide evenly into image width. \"\n",
    "                        \"{0} pixels of information will be lost\".format(h_step_margin))\n",
    "        v_step_space = img.shape[0] - self.shingle_size.rows\n",
    "        # number of pixels left over on bottom edge\n",
    "        v_step_margin = v_step_space % vstep\n",
    "        if v_step_margin != 0:\n",
    "            logger = logging.getLogger(__name__)\n",
    "            logger.debug(\"Vertical step/window settings do not divide evenly into image width. \"\n",
    "                        \"{0} pixels of information may be lost\".format(v_step_margin))\n",
    "        \n",
    "    def __iter__(self):\n",
    "        for row_i in xrange(0, self.img.shape[0] - self.shingle_size[0], self.vstep):\n",
    "            for col_j in xrange(0, self.img.shape[1] - self.shingle_size[1], self.hstep):\n",
    "                logger = logging.getLogger(__name__)\n",
    "                logger.info(\"Row {0}, Col {1}\".format(row_i, col_j))\n",
    "                end_col = col_j + self.shingle_size[1]\n",
    "                end_row = row_i + self.shingle_size[0]\n",
    "                yield self.img[row_i:end_row, col_j:end_col]\n",
    "                \n",
    "\n",
    "def zero_one(x):\n",
    "    \"\"\" Normalize byte-sized integer to 0-1 and flip it so 255 (white)\n",
    "    maps to 0.0\n",
    "    \"\"\"\n",
    "    x = 1. - (x/255.)\n",
    "    return x\n",
    "                \n",
    "def shingles_4_inference(authors_fragments_set, hstep=90, vstep=90,\n",
    "                         shingle_size=StepShingler.ShingleSize(rows=120, cols=120),\n",
    "                         var_threshold=None, postprocess=zero_one,\n",
    "                         verbose=False):\n",
    "    \"\"\" Given a dictionary-like object (e.g. HDF5 Groups, etc.) of\n",
    "    author-keyed fragments, iterate over individual authors, fragments,\n",
    "    and yield pairs of shingle (using deterministic step shingling) and author id.\n",
    "    \n",
    "    Arguments:\n",
    "        authors_fragments_set -- dictionary-like object\n",
    "        hstep -- horizontal step size in pixels/cols\n",
    "        vstep -- vertical step size in pixels/rows\n",
    "        shingle_size -- (rows, cols) tuple indicating size of shingle\n",
    "            StepShingler.ShingleSize provides a useful namedtuple to avoid \n",
    "            parameter order confusion\n",
    "        var_threshold -- float or None; if given, do not yield any shingle whose\n",
    "            variance falls below this quantity\n",
    "        verbose -- if True, will warn on fragments where there are unshingled pixels at the right\n",
    "            or bottom edge\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        if verbose:\n",
    "            old_level = logging.getLogger(__name__).getEffectiveLevel()\n",
    "            logging.getLogger(__name__).setLevel(logging.INFO)\n",
    "        for author_key in authors_fragments_set:\n",
    "            logger=logging.getLogger(__name__); logger.info(\"Author: {0}\".format(author_key))\n",
    "            author_fragments = authors_fragments_set[author_key]\n",
    "            for fragment_key in author_fragments:\n",
    "                fragment = author_fragments[fragment_key]\n",
    "                logger.info(\"Fragment shape: {0}\".format(fragment.shape))\n",
    "                shingle_iterator = StepShingler(fragment, hstep, vstep, shingle_size)\n",
    "                for shingle in shingle_iterator:\n",
    "                    if postprocess is not None:\n",
    "                        shingle=postprocess(shingle)\n",
    "                    if var_threshold is not None:\n",
    "                        shingle_var = np.var(shingle)\n",
    "                        if shingle_var < var_threshold:\n",
    "                            continue\n",
    "                    yield shingle, author_key, fragment_key\n",
    "    finally:\n",
    "        if verbose:\n",
    "            logging.getLogger(__name__).setLevel(old_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-183aab5edaa7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;31m#demo_shingles()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m \u001b[0mdemo_shingle_iteration\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-6-183aab5edaa7>\u001b[0m in \u001b[0;36mdemo_shingle_iteration\u001b[1;34m()\u001b[0m\n\u001b[0;32m     42\u001b[0m             \u001b[1;32mprint\u001b[0m \u001b[1;34m\"Variance: {0}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshingle_var\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m             \u001b[0mIPython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclear_output\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.15\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;31m#demo_shingles()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def demo_shingles():\n",
    "    # get an ICDAR image\n",
    "    icdar_path = \"/fileserver/icdar13/benchmarking-processed/author_icdar_be.hdf5\"\n",
    "    icdar_hdf5 = h5py.File(icdar_path, \"r\")\n",
    "    img = icdar_hdf5['001']['001_1.tif']\n",
    "    \n",
    "    inf_shingler = StepShingler(img, hstep=90, vstep=120, shingle_size=(120,120))\n",
    "\n",
    "    plt.figure(figsize=(10, 3))\n",
    "    for i, shingle in enumerate(inf_shingler):\n",
    "        plt.subplot(1,9,i+1)\n",
    "        plt.imshow(shingle,cmap='gray')\n",
    "        plt.tick_params(\n",
    "            axis='both',\n",
    "            which='both',      \n",
    "            bottom='off',      \n",
    "            top='off',        \n",
    "            left='off',\n",
    "            right='off',\n",
    "            labelbottom='off',\n",
    "            labelleft='off') \n",
    "\n",
    "        if (i+1) % 9 == 0:\n",
    "            plt.show()\n",
    "            break\n",
    "            \n",
    "def demo_shingle_iteration():\n",
    "    # get ICDAR images\n",
    "    icdar_path = \"/fileserver/icdar13/benchmarking-processed/author_icdar_be.hdf5\"\n",
    "    icdar_hdf5 = h5py.File(icdar_path, \"r\")\n",
    "\n",
    "    icdar_shingles = shingles_4_inference(icdar_hdf5, var_threshold=0.025, verbose=False)\n",
    "    if icdar_shingles is not None:\n",
    "        for icdar_shingle, author_id, fragment_id in icdar_shingles:\n",
    "            logger=logging.getLogger(__name__)\n",
    "            logger.info(icdar_shingle.shape)\n",
    "            #a2p.display_img_array(icdar_shingle)\n",
    "            plt.imshow(icdar_shingle, cmap='gray')\n",
    "            plt.show()\n",
    "            print \"Author: {0}, Fragment: {1}\".format(author_id, fragment_id)\n",
    "            shingle_var = np.var(icdar_shingle.reshape(-1))\n",
    "            print \"Variance: {0}\".format(shingle_var)\n",
    "            IPython.display.clear_output(wait=True)\n",
    "            time.sleep(0.15)\n",
    "            \n",
    "#demo_shingles()\n",
    "demo_shingle_iteration()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "iam_m = IAM_MiniBatcher(hdf5_file, num_authors, num_forms_per_author, shingle_dim=shingle_dim, default_mode=MiniBatcher.TRAIN, batch_size=batch_size, train_pct=1.0, test_pct=0.0, val_pct = 0.0)\n",
    "\n",
    "[X_test, Y_test] = iam_m.get_train_batch(batch_size*20)\n",
    "print \"Shape=\"+str(X_test.shape)+\", Max=\"+str(X_test.max())\n",
    "\n",
    "plt.clf\n",
    "plt.subplots(3,3)\n",
    "plt.tight_layout()\n",
    "s = np.random.choice(32,9, replace=False)\n",
    "\n",
    "for i in xrange(9):\n",
    "    plt.subplot(3,3,i+1)\n",
    "    plt.imshow(X_test[s[i]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load a neural network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling model\n",
      "Finished compilation\n",
      "Getting the first validation batch\n",
      "Finished getting 320 data points\n"
     ]
    }
   ],
   "source": [
    "model=fielnet(neural_network_params, layer='fc7')\n",
    "print \"Compiling model\"\n",
    "sgd = SGD(lr=0.1, decay=1e-6, momentum=0.7, nesterov=False)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd)\n",
    "print \"Finished compilation\"\n",
    "\n",
    "print \"Getting the first validation batch\"\n",
    "[X_val, Y_val] = iam_m.get_train_batch(batch_size*10)\n",
    "X_val = np.expand_dims(X_val, 1)\n",
    "Y_val = to_categorical(Y_val, num_authors)\n",
    "print \"Finished getting \"+str(batch_size*10)+\" data points\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Unclear if this is needed\n",
    "from PIL import Image\n",
    "def randangle(batch):\n",
    "    newbatch = np.zeros(batch.shape)\n",
    "    for i,im in enumerate(batch):\n",
    "        imangle = np.asarray(Image.fromarray(im.squeeze()).rotate(7.5*np.random.randn()))\n",
    "        newbatch[i]=imangle\n",
    "    return newbatch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural network feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features = np.zeros(  )\n",
    "for batch_iter in xrange(total_iters):\n",
    "    [X_train, Y_train] = iam_m.get_train_batch(batch_size*100)\n",
    "    X_train = np.expand_dims(X_train, 1)\n",
    "    features[batch_iter] = model.predict(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Feature aggregator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Features for Classifier? (Into Train/Test/Validation?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
