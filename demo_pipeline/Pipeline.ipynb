{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference Pipeline\n",
    "\n",
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: GeForce GTX 980\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import sys\n",
    "sys.path.append('../../d-script/')\n",
    "\n",
    "# Neural network stuff\n",
    "from fielutil import load_verbatimnet\n",
    "from featextractor import extract_imfeats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Do you want to load the features in? Or save them to a file?\n",
    "load_features = False\n",
    "# All the images that you require extraction should be in this HDF5 file\n",
    "# hdf5images='icdar13data/benchmarking-processed/icdar_be.hdf5'\n",
    "hdf5images = 'icdar13data/experimental-processed/icdar13_ex.hdf5'\n",
    "# This is the file that you will load the features from or save the features to\n",
    "# featurefile = 'icdar13data/benchmarking-processed/icdar13be_fiel657.npy'\n",
    "featurefile = 'icdar13data/experimental-processed/icdar13ex_fiel657.npy'\n",
    "# This is the neural networks and parameters you are deciding to use\n",
    "paramsfile = '/fileserver/iam/iam-processed/models/fiel_657.hdf5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full image HDF5 file\n",
    "\n",
    "Each entry in the HDF5 file is a full image/form/document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labels = h5py.File(hdf5images).keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load feature extractor neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Establishing Fiel's verbatim network\n",
      "Compiled neural network up to FC7 layer\n"
     ]
    }
   ],
   "source": [
    "vnet = load_verbatimnet( 'fc7', paramsfile=paramsfile )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image features\n",
    "\n",
    "Currently taken as averages of all shard features in the image. You can either load them or extract everything manually, depending on if you have the .npy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin extracting features fromicdar13data/experimental-processed/icdar13_ex.hdf5\n",
      "Loaded 1176 shards in and predicting on image 027_1.tif\n",
      "1176/1176 [==============================] - 0s     \n",
      "Loaded 1344 shards in and predicting on image 027_2.tif\n",
      "1344/1344 [==============================] - 0s     \n",
      "Loaded 1428 shards in and predicting on image 027_3.tif\n",
      "1428/1428 [==============================] - 0s     \n",
      "Loaded 1596 shards in and predicting on image 027_4.tif\n",
      "1596/1596 [==============================] - 0s     \n",
      "Loaded 840 shards in and predicting on image 028_1.tif\n",
      "840/840 [==============================] - 0s     \n",
      "Loaded 924 shards in and predicting on image 028_2.tif\n",
      "924/924 [==============================] - 0s     \n",
      "Loaded 756 shards in and predicting on image 028_3.tif\n",
      "756/756 [==============================] - 0s     \n",
      "Loaded 1008 shards in and predicting on image 028_4.tif\n",
      "1008/1008 [==============================] - 0s     \n",
      "Loaded 756 shards in and predicting on image 029_1.tif\n",
      "756/756 [==============================] - 0s     \n",
      "Loaded 840 shards in and predicting on image 029_2.tif\n",
      "840/840 [==============================] - 0s     \n",
      "Loaded 924 shards in and predicting on image 029_3.tif\n",
      "924/924 [==============================] - 0s     \n",
      "Loaded 1008 shards in and predicting on image 029_4.tif\n",
      "1008/1008 [==============================] - 0s     \n",
      "Loaded 924 shards in and predicting on image 030_1.tif\n",
      "924/924 [==============================] - 0s     \n",
      "Loaded 1008 shards in and predicting on image 030_2.tif\n",
      "1008/1008 [==============================] - 0s     \n",
      "Loaded 1092 shards in and predicting on image 030_3.tif\n",
      "1092/1092 [==============================] - 0s     \n",
      "Loaded 1428 shards in and predicting on image 030_4.tif\n",
      "1428/1428 [==============================] - 0s     \n",
      "Loaded 1008 shards in and predicting on image 031_1.tif\n",
      "1008/1008 [==============================] - 0s     \n",
      "Loaded 1092 shards in and predicting on image 031_2.tif\n",
      "1092/1092 [==============================] - 0s     \n",
      "Loaded 1176 shards in and predicting on image 031_3.tif\n",
      "1176/1176 [==============================] - 0s     \n",
      "Loaded 1428 shards in and predicting on image 031_4.tif\n",
      "1428/1428 [==============================] - 0s     \n",
      "Loaded 1176 shards in and predicting on image 032_1.tif\n",
      "1176/1176 [==============================] - 0s     "
     ]
    }
   ],
   "source": [
    "if load_features:\n",
    "    imfeats = np.load(featurefile)\n",
    "else:\n",
    "    print \"Begin extracting features from\"+hdf5images\n",
    "    imfeats = extract_imfeats( hdf5images, vnet )\n",
    "    np.save( featurefile, imfeats )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "imfeats = ( imfeats.T / np.linalg.norm( imfeats, axis=1 ) ).T\n",
    "F = imfeats.dot(imfeats.T)\n",
    "np.fill_diagonal( F , -1 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate classifier on HDF5 file (ICDAR 2013)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Top k (soft criteria)\n",
    "k = 10\n",
    "# Max top (hard criteria)\n",
    "maxtop = 2\n",
    "\n",
    "# Run through the adjacency matrix\n",
    "softcorrect = 0\n",
    "hardcorrect = 0\n",
    "totalnum = 0\n",
    "for j, i in enumerate(F):\n",
    "    topk = i.argsort()[-k:]\n",
    "    # Soft criteria\n",
    "    if j/4 in topk/4:\n",
    "        softcorrect += 1\n",
    "    totalnum +=1\n",
    "    # Hard criteria\n",
    "    hardcorrect+= sum([1 for jj in (j/4 == topk[-maxtop:]/4) if jj])\n",
    "    \n",
    "# Print out results    \n",
    "print \"Top %d (soft criteria) = %f\" %( k, (softcorrect+0.0) / totalnum )\n",
    "print \"Top %d (hard criteria) = %f\" %( k, (hardcorrect+0.0) / totalnum / maxtop )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
