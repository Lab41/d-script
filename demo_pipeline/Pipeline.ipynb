{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference Pipeline\n",
    "\n",
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: GeForce GTX 980\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import sys\n",
    "sys.path.append('../../d-script/')\n",
    "\n",
    "# Neural network stuff\n",
    "from fielutil import load_verbatimnet\n",
    "from featextractor import extract_imfeats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Do you want to load the features in? Or save them to a file?\n",
    "load_features = True\n",
    "# All the images that you require extraction should be in this HDF5 file\n",
    "hdf5images='icdar13data/benchmarking-processed/icdar_be.hdf5'\n",
    "# This is the file that you will load the features from or save the features to\n",
    "featurefile = 'icdar13data/benchmarking-processed/icdar13be_fiel1k.npy'\n",
    "# This is the neural networks and parameters you are deciding to use\n",
    "paramsfile = '/fileserver/iam/iam-processed/models/fiel_1k.hdf5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full image HDF5 file\n",
    "\n",
    "Each entry in the HDF5 file is a full image/form/document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = h5py.File(hdf5images).keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load feature extractor neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Establishing Fiel's verbatim network\n",
      "Compiled neural network up to FC7 layer\n"
     ]
    }
   ],
   "source": [
    "vnet = load_verbatimnet( 'fc7', paramsfile=paramsfile )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image features\n",
    "\n",
    "Currently taken as averages of all shard features in the image. You can either load them or extract everything manually, depending on if you have the .npy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if load_features:\n",
    "    imfeats = np.load(featurefile)\n",
    "else:\n",
    "    imfeats = extract_imfeats( hdf5name, vnet )\n",
    "    np.save( featurefile )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "imfeats = ( imfeats.T / np.linalg.norm( imfeats, axis=1 ) ).T\n",
    "F = imfeats.dot(imfeats.T)\n",
    "np.fill_diagonal( F , -1 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate classifier on HDF5 file (ICDAR 2013)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 (soft criteria) = 0.890000\n",
      "Top 10 (hard criteria) = 0.508500\n"
     ]
    }
   ],
   "source": [
    "# Top k (soft criteria)\n",
    "k = 10\n",
    "# Max top (hard criteria)\n",
    "maxtop = 2\n",
    "\n",
    "# Run through the adjacency matrix\n",
    "softcorrect = 0\n",
    "hardcorrect = 0\n",
    "totalnum = 0\n",
    "for j, i in enumerate(F):\n",
    "    topk = i.argsort()[-k:]\n",
    "    # Soft criteria\n",
    "    if j/4 in topk/4:\n",
    "        softcorrect += 1\n",
    "    totalnum +=1\n",
    "    # Hard criteria\n",
    "    hardcorrect+= sum([1 for jj in (j/4 == topk[-maxtop:]/4) if jj])\n",
    "    \n",
    "# Print out results    \n",
    "print \"Top %d (soft criteria) = %f\" %( k, (softcorrect+0.0) / totalnum )\n",
    "print \"Top %d (hard criteria) = %f\" %( k, (hardcorrect+0.0) / totalnum / maxtop )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
