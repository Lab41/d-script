{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: GeForce GTX TITAN X (CNMeM is disabled)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from optparse import OptionParser\n",
    "\n",
    "# Required libraries\n",
    "import h5py\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.layers.normalization import BatchNormalization as BN\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "# d-script imports\n",
    "from data_iters.minibatcher import MiniBatcher\n",
    "from data_iters.iam_hdf5_iterator import IAM_MiniBatcher"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word level document sharding\n",
    "#### Be sure to set use_form=True due to HDF5 structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hdf5_file = '/fileserver/icdar13/benchmarking-processed/author_icdar_be.hdf5'\n",
    "num_authors=100\n",
    "# num_forms_per_author=-1\n",
    "num_forms_per_author=4\n",
    "shingle_dim=(120,1909)\n",
    "shingle_dim=(120,120)\n",
    "use_form=True\n",
    "\n",
    "batch_size=32\n",
    "lr = 0.01\n",
    "total_iters=5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Call the minibatcher and check the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s = round(1e6*(0.7+0.2+0.1))==1e6\n",
    "print s\n",
    "\n",
    "iam_m = IAM_MiniBatcher(hdf5_file, num_authors, num_forms_per_author, shingle_dim=shingle_dim, default_mode=MiniBatcher.TRAIN, batch_size=batch_size, train_pct=1.0, test_pct=0.0, val_pct = 0.0)\n",
    "\n",
    "[X_test, Y_test] = iam_m.get_train_batch(batch_size*20)\n",
    "print \"Shape=\"+str(X_test.shape)+\", Max=\"+str(X_test.max())\n",
    "\n",
    "plt.clf\n",
    "plt.subplots(3,3)\n",
    "plt.tight_layout()\n",
    "s = np.random.choice(32,9, replace=False)\n",
    "\n",
    "for i in xrange(9):\n",
    "    plt.subplot(3,3,i+1)\n",
    "    plt.imshow(X_test[s[i]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the neural network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Convolution2D(48, 12, 12,\n",
    "                    border_mode='valid',\n",
    "                    input_shape=(1, shingle_dim[0], shingle_dim[1])))\n",
    "\n",
    "model.add(BN())\n",
    "#model.add(PReLU())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Convolution2D(48, 6, 6))\n",
    "model.add(BN())\n",
    "model.add(Activation('relu'))\n",
    "#model.add(PReLU())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "#model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Convolution2D(128, 6, 6, border_mode = 'valid'))\n",
    "model.add(BN())\n",
    "model.add(Activation('relu'))\n",
    "#    model.add(PReLU())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#    #model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Convolution2D(128, 3, 3, border_mode = 'valid'))\n",
    "model.add(BN())\n",
    "model.add(Activation('relu'))\n",
    "#model.add(PReLU())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128))\n",
    "model.add(BN())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(128))\n",
    "model.add(BN())\n",
    "model.add(Activation('relu'))\n",
    "#model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(num_authors))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "print \"Compiling model\"\n",
    "sgd = SGD(lr=0.1, decay=1e-6, momentum=0.7, nesterov=False)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd)\n",
    "print \"Finished compilation\"\n",
    "\n",
    "\n",
    "print \"Getting the first validation batch\"\n",
    "[X_val, Y_val] = iam_m.get_val_batch(batch_size*10)\n",
    "X_val = np.expand_dims(X_val, 1)\n",
    "Y_val = to_categorical(Y_val, num_authors)\n",
    "print \"Finished getting \"+str(batch_size*10)+\" data points\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "def randangle(batch):\n",
    "    newbatch = np.zeros(batch.shape)\n",
    "    for i,im in enumerate(batch):\n",
    "        imangle = np.asarray(Image.fromarray(im.squeeze()).rotate(7.5*np.random.randn()))\n",
    "        newbatch[i]=imangle\n",
    "    return newbatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for batch_iter in xrange(total_iters):\n",
    "    [X_train, Y_train] = iam_m.get_train_batch(batch_size*100)\n",
    "    X_train = np.expand_dims(X_train, 1)\n",
    "    X_train = randangle(X_train)\n",
    "    Y_train = to_categorical(Y_train, num_authors)\n",
    "    print \"Batch iteration \"+str(batch_iter)+\"/\"+str(total_iters)+\" on \"+str(num_authors)+\" authors.\"\n",
    "    model.fit(X_train, Y_train, batch_size=batch_size, nb_epoch=1, show_accuracy=True, verbose=1, validation_data=(X_val, Y_val))\n",
    "    if (batch_iter % 100)==0 and batch_iter != 0:\n",
    "        model.save_weights('fielnet.hdf5', overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "[X_test, Y_test] = iam_m.get_test_batch(batch_size*10)\n",
    "X_test = np.expand_dims(X_test,1)\n",
    "Y_test = to_categorical(Y_test, num_authors)\n",
    "model.evaluate(X_test, Y_test, batch_size=32, show_accuracy=True, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
