{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference Pipeline\n",
    "\n",
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using gpu device 0: GeForce GTX 980M (CNMeM is disabled)"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned ON\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import sys\n",
    "import logging\n",
    "sys.path.append('..')\n",
    "\n",
    "# Neural network stuff\n",
    "from fielutil import load_verbatimnet\n",
    "from featextractor import extract_imfeats\n",
    "\n",
    "# Logging\n",
    "# logging.getLogger('featextractor').setLevel(logging.DEBUG)\n",
    "%pdb on"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Do you want to load the features in? Or save them to a file?\n",
    "load_features = False\n",
    "\n",
    "# All the images that you require extraction should be in this HDF5 file\n",
    "# hdf5images='icdar13data/benchmarking-processed/icdar_be.hdf5'\n",
    "# hdf5images = 'icdar13data/experimental-processed/icdar13_ex.hdf5'\n",
    "# hdf5images='nmecdata/nmec_scaled_flat.hdf5'\n",
    "hdf5images='/fileserver/nmec-handwriting/flat_nmec_bin_uint8.hdf5'\n",
    "\n",
    "# This is the file that you will load the features from or save the features to\n",
    "# featurefile = 'icdar13data/benchmarking-processed/icdar13be_fiel657.npy'\n",
    "# featurefile = 'icdar13data/experimental-processed/icdar13ex_fiel657.npy'\n",
    "featurefile = '/fileserver/nmec-handwriting/check.15.npy'\n",
    "\n",
    "# This is the neural networks and parameters you are deciding to use\n",
    "paramsfile = '/fileserver/iam/iam-processed/models/fiel_657.hdf5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full image HDF5 file\n",
    "\n",
    "Each entry in the HDF5 file is a full image/form/document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labels = h5py.File(hdf5images).keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load feature extractor neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Establishing Fiel's verbatim network\n",
      "Loaded neural network up to fc7 layer\n"
     ]
    }
   ],
   "source": [
    "vnet = load_verbatimnet( 'fc7', paramsfile=paramsfile )\n",
    "# vnet.compile(loss='mse', optimizer='sgd')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image features\n",
    "\n",
    "Currently taken as averages of all shard features in the image. You can either load them or extract everything manually, depending on if you have the .npy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin extracting features from /fileserver/nmec-handwriting/flat_nmec_bin_uint8.hdf5\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "global name 'shingle_dim' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-e33565c26bef>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mprint\u001b[0m \u001b[1;34m\"Begin extracting features from \"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mhdf5images\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mimfeats\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mextract_imfeats\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mhdf5images\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvnet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvarthresh\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.15\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[1;32mprint\u001b[0m \u001b[0mh5py\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhdf5images\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mfeaturefile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimfeats\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/work/code/repo/d-script/autoencoder/featextractor.py\u001b[0m in \u001b[0;36mextract_imfeats\u001b[1;34m(hdf5name, network, shingle_dims, steps, varthresh)\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;31m# Noise network\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m     \u001b[0mnoisenet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_denoisenet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;31m# Loop through all the images in the HDF5 file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/work/code/repo/d-script/autoencoder/featextractor.py\u001b[0m in \u001b[0;36mload_denoisenet\u001b[1;34m()\u001b[0m\n\u001b[0;32m     37\u001b[0m     model.add(Convolution2D(24, 6, 6,\n\u001b[0;32m     38\u001b[0m                         \u001b[0mborder_mode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'valid'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m                         input_shape=(1, shingle_dim[0], shingle_dim[1])))\n\u001b[0m\u001b[0;32m     40\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mActivation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mFlatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: global name 'shingle_dim' is not defined"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[1;32m/work/code/repo/d-script/autoencoder/featextractor.py\u001b[0m(39)\u001b[0;36mload_denoisenet\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m     37 \u001b[1;33m    model.add(Convolution2D(24, 6, 6,\n",
      "\u001b[0m\u001b[1;32m     38 \u001b[1;33m                        \u001b[0mborder_mode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'valid'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m---> 39 \u001b[1;33m                        input_shape=(1, shingle_dim[0], shingle_dim[1])))\n",
      "\u001b[0m\u001b[1;32m     40 \u001b[1;33m    \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mActivation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m     41 \u001b[1;33m    \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mFlatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "if load_features:\n",
    "    print \"Loading features in from \"+featurefile\n",
    "    imfeats = np.load(featurefile)\n",
    "    print \"Loaded features\"\n",
    "else:\n",
    "    print \"Begin extracting features from \"+hdf5images\n",
    "    imfeats = extract_imfeats( hdf5images, vnet, steps=(5,5), varthresh=0.15 )\n",
    "    print h5py.File(hdf5images).keys()\n",
    "    np.save( featurefile, imfeats )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "imfeats = ( imfeats.T / np.linalg.norm( imfeats, axis=1 ) ).T\n",
    "F = imfeats.dot(imfeats.T)\n",
    "np.fill_diagonal( F , -1 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate classifier on HDF5 file (ICDAR 2013)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Top k (soft criteria)\n",
    "k = 10\n",
    "# Max top (hard criteria)\n",
    "maxtop = 2\n",
    "# Number of examples per image\n",
    "g = 8\n",
    "\n",
    "# Run through the adjacency matrix\n",
    "softcorrect = 0\n",
    "hardcorrect = 0\n",
    "totalnum = 0\n",
    "for j, i in enumerate(F):\n",
    "    topk = i.argsort()[-k:]\n",
    "    # Soft criteria\n",
    "    if j/g in topk/g:\n",
    "        softcorrect += 1\n",
    "    totalnum +=1\n",
    "    # Hard criteria\n",
    "    hardcorrect+= sum([1 for jj in (j/g == topk[-maxtop:]/g) if jj])\n",
    "    \n",
    "# Print out results    \n",
    "print \"Top %d (soft criteria) = %f\" %( k, (softcorrect+0.0) / totalnum )\n",
    "print \"Top %d (hard criteria) = %f\" %( k, (hardcorrect+0.0) / totalnum / maxtop )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "imfeats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
