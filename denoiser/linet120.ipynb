{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from optparse import OptionParser\n",
    "import pickle\n",
    "import h5py\n",
    "\n",
    "# Required neural network libraries\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.layers.normalization import BatchNormalization as BN\n",
    "\n",
    "# Plotting and stuffs (which probably won't work due to X11 issues)\n",
    "import matplotlib.pylab as plt\n",
    "import sys\n",
    "\n",
    "# d-script imports\n",
    "sys.path.append('../')\n",
    "import data_iters\n",
    "from data_iters.hdf5_iterator import Hdf5MiniBatcher\n",
    "from data_iters.archive.iam_iterator import IAM_MiniBatcher\n",
    "from data_iters.minibatcher import MiniBatcher\n",
    "\n",
    "# Denoising stuff\n",
    "from data_iters.CoffeeStainer import *\n",
    "from data_iters.NoiseAdder import *\n",
    "\n",
    "%pdb off"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define which dataset we'd like to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Which training dataset do we want to train from?\n",
    "train_dataset='iam-binlines'\n",
    "noise_dataset='noisedir/bin'\n",
    "\n",
    "# All the images that you require extraction should be in this HDF5 file\n",
    "if train_dataset=='nmec':\n",
    "    hdf5authors='/fileserver/nmec-handwriting/nmec_scaled_author_form.hdf5'\n",
    "    hdf5images='nmecdata/nmec_scaled_flat.hdf5'\n",
    "elif train_dataset=='nmec-bin':\n",
    "    hdf5authors='nmecdata/author_nmec_bin_uint8.hdf5'\n",
    "    hdf5images='nmecdata/flat_nmec_bin_uint8.hdf5'\n",
    "elif train_dataset=='icdar-ex':\n",
    "    hdf5authors='/fileserver/icdar13/experimental-processed/author_icdar13_ex.hdf5'\n",
    "    hdf5images='/fileserver/icdar13/experimental-processed/icdar13_ex.hdf5'\n",
    "elif train_dataset=='icdar-be':\n",
    "    hdf5authors='/fileserver/icdar13/benchmarking-processed/author_icdar_be.hdf5'\n",
    "    hdf5images='/fileserver/icdar13/benchmarking-processed/icdar13_be.hdf5'\n",
    "elif train_dataset=='iam-words':\n",
    "    hdf5authors='/fileserver/iam/iam-processed/words/author_words.hdf5'\n",
    "elif train_dataset=='iam-binwords':\n",
    "    hdf5authors='/fileserver/iam/iam-binary/iam_author_words_bin.hdf5'\n",
    "    hdf5images='/fileserver/iam/iam-binary/iam_flat_words_bin.hdf5'\n",
    "elif train_dataset=='iam-lines':\n",
    "    hdf5authors='/fileserver/iam/iam-processed/lines/author_lines.hdf5'\n",
    "elif train_dataset=='iam-binlines':\n",
    "    hdf5authors='/fileserver/iam/iam-binary/iam_author_lines_bin.hdf5'\n",
    "    hdf5images='/fileserver/iam/iam-binary/iam_flat_lines_bin.hdf5'\n",
    "elif train_dataset=='iam_binforms':\n",
    "    hdf5authors='/fileserver/iam/iam-binary/iam_author_forms_bin.hdf5'\n",
    "else:\n",
    "    hdf5authors='/fileserver/iam/iam-processed/forms/author_forms.hdf5'\n",
    "    \n",
    "# Setup HDF5 Files\n",
    "labels = h5py.File(hdf5authors, 'r')\n",
    "# num_authors=len(labels)\n",
    "# num_forms_per_author=-1\n",
    "num_authors=300\n",
    "num_forms_per_author=10\n",
    "shingle_dim=(120,120)\n",
    "batch_size=32\n",
    "load_size=batch_size*1000\n",
    "iterations = 10000\n",
    "lr = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get both the minibatcher and the noisebatcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mini_m = IAM_MiniBatcher(hdf5authors, num_authors, num_forms_per_author,\n",
    "                            shingle_dim=shingle_dim, default_mode=MiniBatcher.TRAIN,\n",
    "                            batch_size=load_size)\n",
    "noise_m = NoiseAdder(noise_dataset)\n",
    "\n",
    "(Y,Dummy) = mini_m.get_batch(10)\n",
    "rng = np.random.RandomState(100)\n",
    "X = noise_m.add_noise_batch(Y, rng=rng, shingle_dim=shingle_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot example noise images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "for i in xrange(4):\n",
    "    plt.subplots(1,2)\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.imshow(Y[i], cmap='gray')\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.imshow(X[i], cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Define the Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import noisenet\n",
    "reload(noisenet)\n",
    "model = noisenet.conv4p2c_model(shingle_dim=shingle_dim)\n",
    "\n",
    "batchtrack = 0  # Keep track of the batches for start & stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "from IPython.display import clear_output\n",
    "\n",
    "load_size=32000\n",
    "\n",
    "X_nonthresh = np.zeros( (load_size,)+shingle_dim )\n",
    "for batch_iter in xrange(iterations):\n",
    "    \n",
    "    print \"Getting batch number \"+str(batch_iter)+\".\"\n",
    "    sys.stdout.flush()\n",
    "    (X_image, Y_train) = mini_m.get_batch(load_size)\n",
    "    # print \"Thresholding the image\"\n",
    "    # X_nonthresh[:] = X_image\n",
    "    # for im in X_image:\n",
    "    #     X_image[ X_image < (0.75*im.max()) ] = 0\n",
    "    #     X_image[ X_image >=(0.75*im.max()) ] = 255\n",
    "    print \"Adding noise to batch\"\n",
    "    sys.stdout.flush()\n",
    "        \n",
    "    X_noise = noise_m.add_noise_batch(X_image, rng=rng, shingle_dim=shingle_dim)\n",
    "    print \"Finished adding noise to batch\"\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "    X_noise = 1.0 - X_noise/255.0    \n",
    "    X_image = 1.0 - X_image/255.0\n",
    "    print \"Bounded image pixel values\"\n",
    "    \n",
    "    X_image = np.expand_dims(X_image, 1)\n",
    "    X_noise = np.expand_dims(X_noise, 1)\n",
    "    print \"Reshape and preprocessed to scale between 0 and 1\"\n",
    "    sys.stdout.flush()\n",
    "\n",
    "    model.fit(X_noise, X_image, batch_size=batch_size, nb_epoch=1, show_accuracy=True, verbose=1) #, validation_data=(X_test, Y_test))\n",
    "    \n",
    "    ############################# VISUALIZATION #############################\n",
    "    # Blank image with random noise at the beginning (for the first image)\n",
    "    X_clean_noise = noise_m.add_noise_np( 255*np.ones(shingle_dim), rng=rng, shingle_dim=shingle_dim )\n",
    "    X_clean_noise = 1.0 - np.expand_dims( np.expand_dims(X_clean_noise,0), 0 )/255.0\n",
    "    X_clean_noise_output = model.predict( X_clean_noise )\n",
    "    X_clean_noise_output = X_clean_noise_output.reshape( X_clean_noise.shape )\n",
    "    plt.subplots(1,2)\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.imshow( 1.0 - X_clean_noise.squeeze(), cmap='gray' )\n",
    "    plt.title('Noise Image')\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.imshow(1.0 - X_clean_noise_output.squeeze(), cmap='gray')\n",
    "\n",
    "    X_example = model.predict( X_noise[:5] )\n",
    "    X_example = X_example.reshape( (5,)+X_noise.shape[2:] )\n",
    "    clear_output()\n",
    "    for i, exim in enumerate(X_example):\n",
    "        plt.subplots(1,3,figsize=(5,5))\n",
    "        plt.subplot(1,3,3)\n",
    "        plt.imshow(1.0-X_example[i], cmap='gray')\n",
    "        plt.title('Predicted Image')\n",
    "        plt.subplot(1,3,2)\n",
    "        plt.imshow(1.0-X_image[i].reshape(X_noise.shape[2:]), cmap='gray')\n",
    "        plt.title('Targeted Image')\n",
    "        plt.subplot(1,3,1)\n",
    "        plt.imshow(1.0-X_noise[i][0], cmap='gray')\n",
    "        plt.title('Input Noisy Image')\n",
    "    plt.show()\n",
    "        \n",
    "    if (batch_iter % 25) == 0:\n",
    "        model.save_weights('conv4p2_linet120-iambin-tifs.hdf5', overwrite=True)\n",
    "    batchtrack += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(X_image, Y_train) = mini_m.get_batch(64)\n",
    "print X_image.shape\n",
    "X_noise = noise_m.add_noise_batch(X_image, rng=rng, shingle_dim=shingle_dim)\n",
    "X_noise = 1.0 - X_noise/255.0    \n",
    "print X_noise.shape\n",
    "X_image = X_image.reshape( (64, np.prod(X_image.shape[1:])))\n",
    "X_image = 1.0 - X_image/255.0\n",
    "print X_image.shape\n",
    "X_noise = np.expand_dims(X_noise, 1)\n",
    "\n",
    "shingle_dim\n",
    "\n",
    "model.save_weights('conv4p2_linet120-iambin-tifs.hdf5')\n",
    "# X_noise = X_noise.reshape( (load_size, np.prod(X_noise.shape[1:])))\n",
    "# print X_noise.reshape((load_size, np.prod(X_noise.shape[1:])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f = h5py.File('/fileserver/iam/iam-binary/iam_author_lines_bin.hdf5','r')\n",
    "print f['001']['a01-000x-00'].value\n",
    "plt.imshow(f['001']['a01-000x-00'])\n",
    "batchtrack = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batchtrack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
