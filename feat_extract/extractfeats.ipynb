{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: GeForce GTX TITAN X (CNMeM is disabled)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from optparse import OptionParser\n",
    "import pickle\n",
    "import scipy.misc as smi\n",
    "\n",
    "# Required libraries\n",
    "import h5py\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.layers.normalization import BatchNormalization as BN\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "sys.path.append('/work/code/repo/d-script/')\n",
    "# d-script imports\n",
    "from data_iters.minibatcher import MiniBatcher\n",
    "from data_iters.iam_hdf5_iterator import IAM_MiniBatcher\n",
    "\n",
    "from fielutil import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data ingest\n",
    "\n",
    "* Mini-batcher ingestion of data from HDF5 file specified at the beginning\n",
    "* Direct image to do inference on, where for memory's sake, we've cut down the original image size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hdf5_file = '/memory/author_lines.hdf5'\n",
    "num_forms_per_author=50; batch_size=32; num_authors=47; shingle_dim=(120,120); use_form=True\n",
    "\n",
    "iam_m = IAM_MiniBatcher(hdf5_file, num_authors, num_forms_per_author, shingle_dim=shingle_dim, use_form=use_form, default_mode=MiniBatcher.TRAIN, batch_size=batch_size)\n",
    "[X_test, Y_test] = iam_m.get_test_batch(batch_size*20)\n",
    "X_test = np.expand_dims(X_test, 1)\n",
    "X_test = randangle(X_test)\n",
    "Y_test = to_categorical(Y_test, num_authors)\n",
    "\n",
    "im = smi.imread('/fileserver/iam/forms/h07-025a.png')\n",
    "im = 1.0-im/256.0\n",
    "maxx, maxy = im.shape\n",
    "maxx = maxx/3\n",
    "maxy = maxy/3\n",
    "halfim = im[ :maxx, :maxy ]\n",
    "halfim = np.expand_dims( np.expand_dims( halfim, 0 ), 0 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert Original Dense Network to Convolutional Network\n",
    "\n",
    "The following implementation is somewhat memory inefficient in that it first creates a network and then loads from that network into the feature network. What would be more efficient would be to read directly from the *.hdf5* file into the feature network. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading original weights into GPU memory\n",
      "Finished loading, now begin iterating through layers to copy over to feature model\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "Layer shape (48, 1169, 815) not compatible with weight shape (48, 109, 109).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-9f0ec4668633>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     44\u001b[0m         \u001b[0mfeatmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mlayer\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m             \u001b[0mfeatmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[1;34m\"Model created and weights loaded in\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/Keras-0.2.0-py2.7.egg/keras/layers/normalization.pyc\u001b[0m in \u001b[0;36mset_weights\u001b[1;34m(self, weights)\u001b[0m\n\u001b[0;32m     55\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrunning_mean\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfloatX\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrunning_std\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfloatX\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 57\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBatchNormalization\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     58\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_output\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/Keras-0.2.0-py2.7.egg/keras/layers/core.pyc\u001b[0m in \u001b[0;36mset_weights\u001b[1;34m(self, weights)\u001b[0m\n\u001b[0;32m    138\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 140\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Layer shape %s not compatible with weight shape %s.\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    141\u001b[0m             \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfloatX\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mException\u001b[0m: Layer shape (48, 1169, 815) not compatible with weight shape (48, 109, 109)."
     ]
    }
   ],
   "source": [
    "print \"Loading original weights into GPU memory\"\n",
    "model = fielnet('../convnets/fielnet/fielnet.hdf5', layer='fc8')\n",
    "# When we flatten a convolutional layer, we need to know what the original dimensions were\n",
    "flatten_shape = [layer.input_shape for layer in model.layers if type(layer)==Flatten][0]\n",
    "flattened = False\n",
    "\n",
    "print \"Finished loading, now begin iterating through layers to copy over to feature model\"\n",
    "featmodel = Sequential()\n",
    "for layer in model.layers:\n",
    "    # The first layer\n",
    "    if layer == model.layers[0] and type(layer)==Convolution2D:\n",
    "        Wl = layer.get_weights()[0]\n",
    "        bl = layer.get_weights()[1]\n",
    "        convshape = Wl.shape[2:]\n",
    "        convshape = (Wl.shape[0],)+convshape\n",
    "        featmodel.add(Convolution2D( *convshape, border_mode=layer.border_mode,\n",
    "                                     input_shape=(1, maxx, maxy), weights=[Wl,bl]))\n",
    "    # From the layer \"Flatten\" on, we'll need to make changes to Dense layers\n",
    "    elif type( layer ) == Flatten:\n",
    "        convshape = flatten_shape[-2:]\n",
    "        flattened = True\n",
    "    # Take the convolutional shape and add our newest layer\n",
    "    elif type( layer ) == Dense:\n",
    "        convshape = (layer.output_shape[-1],)+convshape\n",
    "        Wl = layer.get_weights()[0]\n",
    "        Wl = Wl.T.reshape( convshape[0], Wl.shape[0]/np.product(convshape[1:]), *convshape[1:] )\n",
    "        # Flip all the weights for convolution\n",
    "        for d0 in xrange(Wl.shape[0]): \n",
    "            for d1 in xrange(Wl.shape[1]):\n",
    "                Wl[d0][d1] = np.flipud( np.fliplr( Wl[d0][d1] ))\n",
    "        bl = layer.get_weights()[1]\n",
    "        featmodel.add(Convolution2D( *convshape, border_mode = 'valid', weights=[Wl,bl] ))\n",
    "        convshape = (1,1)\n",
    "    elif type( layer ) == BN and flattened:\n",
    "        weights = [ np.expand_dims(np.expand_dims(weight,1),1)  for weight in layer.get_weights() ]\n",
    "        featmodel.add (layer )\n",
    "        featmodel.layers[-1].set_weights( weights )\n",
    "    else:\n",
    "        weights = layer.get_weights()\n",
    "        featmodel.add( layer )\n",
    "        if weights:\n",
    "            featmodel.layers[-1].set_weights(weights)\n",
    "\n",
    "print \"Model created and weights loaded in\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"The first convolutional weight size expects an image of size \"+str(maxx)+\"x\"+str(maxy)\n",
    "featmodel.compile( loss='mse', optimizer='sgd' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "halfimacts = featmodel.predict(halfim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "numcols = 3\n",
    "numrows = 16\n",
    "\n",
    "for j in xrange(numrows):\n",
    "    plt.figure()\n",
    "    for i in xrange(numcols):\n",
    "        if (j*numcols+i) < halfimacts.shape[1]:\n",
    "            plt.subplot(1,numcols,i+1)\n",
    "            plt.imshow(halfimacts[0,j*numcols+i,:,:])\n",
    "            plt.title('Neuron '+str(j*numcols+i))\n",
    "            plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
